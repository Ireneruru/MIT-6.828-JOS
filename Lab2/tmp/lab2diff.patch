diff --git a/COPYRIGHT b/COPYRIGHT
new file mode 100644
index 0000000..6a0270c
--- /dev/null
+++ b/COPYRIGHT
@@ -0,0 +1,155 @@
+Most of the source files in this directory are derived from the Exokernel,
+which is:
+
+/*
+ * Copyright (C) 1997 Massachusetts Institute of Technology 
+ *
+ * This software is being provided by the copyright holders under the
+ * following license. By obtaining, using and/or copying this software,
+ * you agree that you have read, understood, and will comply with the
+ * following terms and conditions:
+ *
+ * Permission to use, copy, modify, distribute, and sell this software
+ * and its documentation for any purpose and without fee or royalty is
+ * hereby granted, provided that the full text of this NOTICE appears on
+ * ALL copies of the software and documentation or portions thereof,
+ * including modifications, that you make.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS," AND COPYRIGHT HOLDERS MAKE NO
+ * REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE,
+ * BUT NOT LIMITATION, COPYRIGHT HOLDERS MAKE NO REPRESENTATIONS OR
+ * WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR
+ * THAT THE USE OF THE SOFTWARE OR DOCUMENTATION WILL NOT INFRINGE ANY
+ * THIRD PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS. COPYRIGHT
+ * HOLDERS WILL BEAR NO LIABILITY FOR ANY USE OF THIS SOFTWARE OR
+ * DOCUMENTATION.
+ *
+ * The name and trademarks of copyright holders may NOT be used in
+ * advertising or publicity pertaining to the software without specific,
+ * written prior permission. Title to copyright in this software and any
+ * associated documentation will at all times remain with copyright
+ * holders. See the file AUTHORS which should have accompanied this software
+ * for a list of all copyright holders.
+ *
+ * This file may be derived from previously copyrighted software. This
+ * copyright applies only to those changes made by the copyright
+ * holders listed in the AUTHORS file. The rest of this file is covered by
+ * the copyright notices, if any, listed below.
+ */
+
+Console.c was created consulting the NetBSD pccons driver which is:
+
+/*-
+ * Copyright (c) 1993, 1994, 1995 Charles Hannum.  All rights reserved.
+ * Copyright (c) 1990 The Regents of the University of California.
+ * All rights reserved.
+ *
+ * This code is derived from software contributed to Berkeley by
+ * William Jolitz and Don Ahn.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. All advertising materials mentioning features or use of this software
+ *    must display the following acknowledgement:
+ *	This product includes software developed by the University of
+ *	California, Berkeley and its contributors.
+ * 4. Neither the name of the University nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ */
+
+Kclock.h, sched.h, and printf.h are copyright:
+
+/*
+ * Copyright (C) 1998 Exotec, Inc.
+ *
+ * This software is being provided by the copyright holders under the
+ * following license. By obtaining, using and/or copying this software,
+ * you agree that you have read, understood, and will comply with the
+ * following terms and conditions:
+ *
+ * Permission to use, copy, modify, distribute, and sell this software
+ * and its documentation for any purpose and without fee or royalty is
+ * hereby granted, provided that the full text of this NOTICE appears on
+ * ALL copies of the software and documentation or portions thereof,
+ * including modifications, that you make.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS," AND COPYRIGHT HOLDERS MAKE NO
+ * REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE,
+ * BUT NOT LIMITATION, COPYRIGHT HOLDERS MAKE NO REPRESENTATIONS OR
+ * WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR
+ * THAT THE USE OF THE SOFTWARE OR DOCUMENTATION WILL NOT INFRINGE ANY
+ * THIRD PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS. COPYRIGHT
+ * HOLDERS WILL BEAR NO LIABILITY FOR ANY USE OF THIS SOFTWARE OR
+ * DOCUMENTATION.
+ *
+ * The name and trademarks of copyright holders may NOT be used in
+ * advertising or publicity pertaining to the software without specific,
+ * written prior permission. Title to copyright in this software and any
+ * associated documentation will at all times remain with Exotec, Inc..
+ *
+ * This file may be derived from previously copyrighted software. This
+ * copyright applies only to those changes made by Exotec, Inc. The rest
+ * of this file is covered by the copyright notices, if any, listed below.
+ */
+
+Printf.c is copyright:
+
+/*-
+ * Copyright (c) 1986, 1988, 1991, 1993
+ *	The Regents of the University of California.  All rights reserved.
+ * (c) UNIX System Laboratories, Inc.
+ * All or some portions of this file are derived from material licensed
+ * to the University of California by American Telephone and Telegraph
+ * Co. or Unix System Laboratories, Inc. and are reproduced herein with
+ * the permission of UNIX System Laboratories, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. All advertising materials mentioning features or use of this software
+ *    must display the following acknowledgement:
+ *	This product includes software developed by the University of
+ *	California, Berkeley and its contributors.
+ * 4. Neither the name of the University nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ *	@(#)subr_prf.c	8.3 (Berkeley) 1/21/94
+ */
+
diff --git a/GNUmakefile b/GNUmakefile
index dd64716..bcf95c3 100644
--- a/GNUmakefile
+++ b/GNUmakefile
@@ -87,6 +87,7 @@ CFLAGS := $(CFLAGS) $(DEFS) $(LABDEFS) -O1 -fno-builtin -I$(TOP) -MD
 CFLAGS += -fno-omit-frame-pointer
 CFLAGS += -std=gnu99
 CFLAGS += -static
+
 CFLAGS += -Wall -Wno-format -Wno-unused -Werror -gstabs -m32
 # -fno-tree-ch prevented gcc from sometimes reordering read_ebp() before
 # mon_backtrace()'s function prologue on gcc version: (Debian 4.7.2-5) 4.7.2
diff --git a/Makefrag b/Makefrag
new file mode 100644
index 0000000..3b2982e
--- /dev/null
+++ b/Makefrag
@@ -0,0 +1,89 @@
+#
+# Makefile fragment for JOS kernel.
+# This is NOT a complete makefile;
+# you must run GNU make in the top-level directory
+# where the GNUmakefile is located.
+#
+
+OBJDIRS += kern
+
+KERN_LDFLAGS := $(LDFLAGS) -T kern/kernel.ld -nostdlib
+
+# entry.S must be first, so that it's the first code in the text segment!!!
+#
+# We also snatch the use of a couple handy source files
+# from the lib directory, to avoid gratuitous code duplication.
+KERN_SRCFILES :=	kern/entry.S \
+			kern/entrypgdir.c \
+			kern/init.c \
+			kern/console.c \
+			kern/monitor.c \
+			kern/pmap.c \
+			kern/env.c \
+			kern/kclock.c \
+			kern/picirq.c \
+			kern/printf.c \
+			kern/trap.c \
+			kern/trapentry.S \
+			kern/sched.c \
+			kern/syscall.c \
+			kern/kdebug.c \
+			lib/printfmt.c \
+			lib/readline.c \
+			lib/string.c
+
+# Only build files if they exist.
+KERN_SRCFILES := $(wildcard $(KERN_SRCFILES))
+
+# Binary program images to embed within the kernel.
+KERN_BINFILES := 
+
+KERN_OBJFILES := $(patsubst %.c, $(OBJDIR)/%.o, $(KERN_SRCFILES))
+KERN_OBJFILES := $(patsubst %.S, $(OBJDIR)/%.o, $(KERN_OBJFILES))
+KERN_OBJFILES := $(patsubst $(OBJDIR)/lib/%, $(OBJDIR)/kern/%, $(KERN_OBJFILES))
+
+KERN_BINFILES := $(patsubst %, $(OBJDIR)/%, $(KERN_BINFILES))
+
+# How to build kernel object files
+$(OBJDIR)/kern/%.o: kern/%.c $(OBJDIR)/.vars.KERN_CFLAGS
+	@echo + cc $<
+	@mkdir -p $(@D)
+	$(V)$(CC) -nostdinc $(KERN_CFLAGS) -c -o $@ $<
+
+$(OBJDIR)/kern/%.o: kern/%.S $(OBJDIR)/.vars.KERN_CFLAGS
+	@echo + as $<
+	@mkdir -p $(@D)
+	$(V)$(CC) -nostdinc $(KERN_CFLAGS) -c -o $@ $<
+
+$(OBJDIR)/kern/%.o: lib/%.c $(OBJDIR)/.vars.KERN_CFLAGS
+	@echo + cc $<
+	@mkdir -p $(@D)
+	$(V)$(CC) -nostdinc $(KERN_CFLAGS) -c -o $@ $<
+
+# Special flags for kern/init
+$(OBJDIR)/kern/init.o: override KERN_CFLAGS+=$(INIT_CFLAGS)
+$(OBJDIR)/kern/init.o: $(OBJDIR)/.vars.INIT_CFLAGS
+
+# How to build the kernel itself
+$(OBJDIR)/kern/kernel: $(KERN_OBJFILES) $(KERN_BINFILES) kern/kernel.ld \
+	  $(OBJDIR)/.vars.KERN_LDFLAGS
+	@echo + ld $@
+	$(V)$(LD) -o $@ $(KERN_LDFLAGS) $(KERN_OBJFILES) $(GCC_LIB) -b binary $(KERN_BINFILES)
+	$(V)$(OBJDUMP) -S $@ > $@.asm
+	$(V)$(NM) -n $@ > $@.sym
+
+# How to build the kernel disk image
+$(OBJDIR)/kern/kernel.img: $(OBJDIR)/kern/kernel $(OBJDIR)/boot/boot
+	@echo + mk $@
+	$(V)dd if=/dev/zero of=$(OBJDIR)/kern/kernel.img~ count=10000 2>/dev/null
+	$(V)dd if=$(OBJDIR)/boot/boot of=$(OBJDIR)/kern/kernel.img~ conv=notrunc 2>/dev/null
+	$(V)dd if=$(OBJDIR)/kern/kernel of=$(OBJDIR)/kern/kernel.img~ seek=1 conv=notrunc 2>/dev/null
+	$(V)mv $(OBJDIR)/kern/kernel.img~ $(OBJDIR)/kern/kernel.img
+
+all: $(OBJDIR)/kern/kernel.img
+
+grub: $(OBJDIR)/jos-grub
+
+$(OBJDIR)/jos-grub: $(OBJDIR)/kern/kernel
+	@echo + oc $@
+	$(V)$(OBJCOPY) --adjust-vma=0x10000000 $^ $@
diff --git a/inc/color.h b/inc/color.h
new file mode 100644
index 0000000..ed09ec1
--- /dev/null
+++ b/inc/color.h
@@ -0,0 +1,3 @@
+int FG_COLOR;
+int BG_COLOR;
+int COLOR;
diff --git a/inc/memlayout.h b/inc/memlayout.h
index a537b15..a90a638 100644
--- a/inc/memlayout.h
+++ b/inc/memlayout.h
@@ -47,7 +47,7 @@
  *                     |       Memory-mapped I/O      | RW/--  PTSIZE
  * ULIM, MMIOBASE -->  +------------------------------+ 0xef800000
  *                     |  Cur. Page Table (User R-)   | R-/R-  PTSIZE
- *    UVPT      ---->  +------------------------------+ 0xef400000
+ *    UVPT      ---->  +------------------------------+ show
  *                     |          RO PAGES            | R-/R-  PTSIZE
  *    UPAGES    ---->  +------------------------------+ 0xef000000
  *                     |           RO ENVS            | R-/R-  PTSIZE
diff --git a/inc/memlayout.h~ b/inc/memlayout.h~
new file mode 100644
index 0000000..a537b15
--- /dev/null
+++ b/inc/memlayout.h~
@@ -0,0 +1,188 @@
+#ifndef JOS_INC_MEMLAYOUT_H
+#define JOS_INC_MEMLAYOUT_H
+
+#ifndef __ASSEMBLER__
+#include <inc/types.h>
+#include <inc/mmu.h>
+#endif /* not __ASSEMBLER__ */
+
+/*
+ * This file contains definitions for memory management in our OS,
+ * which are relevant to both the kernel and user-mode software.
+ */
+
+// Global descriptor numbers
+#define GD_KT     0x08     // kernel text
+#define GD_KD     0x10     // kernel data
+#define GD_UT     0x18     // user text
+#define GD_UD     0x20     // user data
+#define GD_TSS0   0x28     // Task segment selector for CPU 0
+
+/*
+ * Virtual memory map:                                Permissions
+ *                                                    kernel/user
+ *
+ *    4 Gig -------->  +------------------------------+
+ *                     |                              | RW/--
+ *                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *                     :              .               :
+ *                     :              .               :
+ *                     :              .               :
+ *                     |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~| RW/--
+ *                     |                              | RW/--
+ *                     |   Remapped Physical Memory   | RW/--
+ *                     |                              | RW/--
+ *    KERNBASE, ---->  +------------------------------+ 0xf0000000      --+
+ *    KSTACKTOP        |     CPU0's Kernel Stack      | RW/--  KSTKSIZE   |
+ *                     | - - - - - - - - - - - - - - -|                   |
+ *                     |      Invalid Memory (*)      | --/--  KSTKGAP    |
+ *                     +------------------------------+                   |
+ *                     |     CPU1's Kernel Stack      | RW/--  KSTKSIZE   |
+ *                     | - - - - - - - - - - - - - - -|                 PTSIZE
+ *                     |      Invalid Memory (*)      | --/--  KSTKGAP    |
+ *                     +------------------------------+                   |
+ *                     :              .               :                   |
+ *                     :              .               :                   |
+ *    MMIOLIM ------>  +------------------------------+ 0xefc00000      --+
+ *                     |       Memory-mapped I/O      | RW/--  PTSIZE
+ * ULIM, MMIOBASE -->  +------------------------------+ 0xef800000
+ *                     |  Cur. Page Table (User R-)   | R-/R-  PTSIZE
+ *    UVPT      ---->  +------------------------------+ 0xef400000
+ *                     |          RO PAGES            | R-/R-  PTSIZE
+ *    UPAGES    ---->  +------------------------------+ 0xef000000
+ *                     |           RO ENVS            | R-/R-  PTSIZE
+ * UTOP,UENVS ------>  +------------------------------+ 0xeec00000
+ * UXSTACKTOP -/       |     User Exception Stack     | RW/RW  PGSIZE
+ *                     +------------------------------+ 0xeebff000
+ *                     |       Empty Memory (*)       | --/--  PGSIZE
+ *    USTACKTOP  --->  +------------------------------+ 0xeebfe000
+ *                     |      Normal User Stack       | RW/RW  PGSIZE
+ *                     +------------------------------+ 0xeebfd000
+ *                     |                              |
+ *                     |                              |
+ *                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *                     .                              .
+ *                     .                              .
+ *                     .                              .
+ *                     |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|
+ *                     |     Program Data & Heap      |
+ *    UTEXT -------->  +------------------------------+ 0x00800000
+ *    PFTEMP ------->  |       Empty Memory (*)       |        PTSIZE
+ *                     |                              |
+ *    UTEMP -------->  +------------------------------+ 0x00400000      --+
+ *                     |       Empty Memory (*)       |                   |
+ *                     | - - - - - - - - - - - - - - -|                   |
+ *                     |  User STAB Data (optional)   |                 PTSIZE
+ *    USTABDATA ---->  +------------------------------+ 0x00200000        |
+ *                     |       Empty Memory (*)       |                   |
+ *    0 ------------>  +------------------------------+                 --+
+ *
+ * (*) Note: The kernel ensures that "Invalid Memory" is *never* mapped.
+ *     "Empty Memory" is normally unmapped, but user programs may map pages
+ *     there if desired.  JOS user programs map pages temporarily at UTEMP.
+ */
+
+
+// All physical memory mapped at this address
+#define	KERNBASE	0xF0000000
+
+// At IOPHYSMEM (640K) there is a 384K hole for I/O.  From the kernel,
+// IOPHYSMEM can be addressed at KERNBASE + IOPHYSMEM.  The hole ends
+// at physical address EXTPHYSMEM.
+#define IOPHYSMEM	0x0A0000
+#define EXTPHYSMEM	0x100000
+
+// Kernel stack.
+#define KSTACKTOP	KERNBASE
+#define KSTKSIZE	(8*PGSIZE)   		// size of a kernel stack
+#define KSTKGAP		(8*PGSIZE)   		// size of a kernel stack guard
+
+// Memory-mapped IO.
+#define MMIOLIM		(KSTACKTOP - PTSIZE)
+#define MMIOBASE	(MMIOLIM - PTSIZE)
+
+#define ULIM		(MMIOBASE)
+
+/*
+ * User read-only mappings! Anything below here til UTOP are readonly to user.
+ * They are global pages mapped in at env allocation time.
+ */
+
+// User read-only virtual page table (see 'uvpt' below)
+#define UVPT		(ULIM - PTSIZE)
+// Read-only copies of the Page structures
+#define UPAGES		(UVPT - PTSIZE)
+// Read-only copies of the global env structures
+#define UENVS		(UPAGES - PTSIZE)
+
+/*
+ * Top of user VM. User can manipulate VA from UTOP-1 and down!
+ */
+
+// Top of user-accessible VM
+#define UTOP		UENVS
+// Top of one-page user exception stack
+#define UXSTACKTOP	UTOP
+// Next page left invalid to guard against exception stack overflow; then:
+// Top of normal user stack
+#define USTACKTOP	(UTOP - 2*PGSIZE)
+
+// Where user programs generally begin
+#define UTEXT		(2*PTSIZE)
+
+// Used for temporary page mappings.  Typed 'void*' for convenience
+#define UTEMP		((void*) PTSIZE)
+// Used for temporary page mappings for the user page-fault handler
+// (should not conflict with other temporary page mappings)
+#define PFTEMP		(UTEMP + PTSIZE - PGSIZE)
+// The location of the user-level STABS data structure
+#define USTABDATA	(PTSIZE / 2)
+
+#ifndef __ASSEMBLER__
+
+typedef uint32_t pte_t;
+typedef uint32_t pde_t;
+
+#if JOS_USER
+/*
+ * The page directory entry corresponding to the virtual address range
+ * [UVPT, UVPT + PTSIZE) points to the page directory itself.  Thus, the page
+ * directory is treated as a page table as well as a page directory.
+ *
+ * One result of treating the page directory as a page table is that all PTEs
+ * can be accessed through a "virtual page table" at virtual address UVPT (to
+ * which uvpt is set in lib/entry.S).  The PTE for page number N is stored in
+ * uvpt[N].  (It's worth drawing a diagram of this!)
+ *
+ * A second consequence is that the contents of the current page directory
+ * will always be available at virtual address (UVPT + (UVPT >> PGSHIFT)), to
+ * which uvpd is set in lib/entry.S.
+ */
+extern volatile pte_t uvpt[];     // VA of "virtual page table"
+extern volatile pde_t uvpd[];     // VA of current page directory
+#endif
+
+/*
+ * Page descriptor structures, mapped at UPAGES.
+ * Read/write to the kernel, read-only to user programs.
+ *
+ * Each struct PageInfo stores metadata for one physical page.
+ * Is it NOT the physical page itself, but there is a one-to-one
+ * correspondence between physical pages and struct PageInfo's.
+ * You can map a struct PageInfo * to the corresponding physical address
+ * with page2pa() in kern/pmap.h.
+ */
+struct PageInfo {
+	// Next page on the free list.
+	struct PageInfo *pp_link;
+
+	// pp_ref is the count of pointers (usually in page table entries)
+	// to this page, for pages allocated using page_alloc.
+	// Pages allocated at boot time using pmap.c's
+	// boot_alloc do not have valid reference count fields.
+
+	uint16_t pp_ref;
+};
+
+#endif /* !__ASSEMBLER__ */
+#endif /* !JOS_INC_MEMLAYOUT_H */
diff --git a/kern/console.c b/kern/console.c
index 7d312a7..aba428e 100644
--- a/kern/console.c
+++ b/kern/console.c
@@ -5,6 +5,7 @@
 #include <inc/kbdreg.h>
 #include <inc/string.h>
 #include <inc/assert.h>
+#include <inc/color.h>
 
 #include <kern/console.h>
 
@@ -164,8 +165,7 @@ cga_putc(int c)
 {
 	// if no attribute given, then use black on white
 	if (!(c & ~0xFF))
-		c |= 0x0700;
-
+	   	c |= COLOR;
 	switch (c & 0xff) {
 	case '\b':
 		if (crt_pos > 0) {
diff --git a/kern/grade-lab1 b/kern/grade-lab1
new file mode 100755
index 0000000..94bcb0f
--- /dev/null
+++ b/kern/grade-lab1
@@ -0,0 +1,44 @@
+#!/usr/bin/env python
+
+import re
+from gradelib import *
+
+r = Runner(save("jos.out"),
+           stop_breakpoint("readline"))
+
+@test(0, "running JOS")
+def test_jos():
+    r.run_qemu()
+
+@test(20, parent=test_jos)
+def test_printf():
+    r.match("6828 decimal is 15254 octal!")
+
+BACKTRACE_RE = r"^ *ebp +f01[0-9a-z]{5} +eip +f0100[0-9a-z]{3} +args +([0-9a-z]+)"
+
+@test(10, parent=test_jos)
+def test_backtrace_count():
+    matches = re.findall(BACKTRACE_RE, r.qemu.output, re.MULTILINE)
+    assert_equal(len(matches), 8)
+
+@test(10, parent=test_jos)
+def test_backtrace_arguments():
+    matches = re.findall(BACKTRACE_RE, r.qemu.output, re.MULTILINE)
+    assert_equal("\n".join(matches[:7]),
+                 "\n".join("%08x" % n for n in [0,0,1,2,3,4,5]))
+
+@test(5, parent=test_jos)
+def test_backtrace_symbols():
+    matches = re.findall(r"kern/init.c:[0-9]+: +([^+]*)\+", r.qemu.output)
+    assert_equal("\n".join(matches[:7]),
+                 "\n".join(["test_backtrace"] * 6 + ["i386_init"]))
+
+@test(5, parent=test_jos)
+def test_backtrace_lines():
+    matches = re.findall(r"([^ ]*init.c:([0-9]+):) +test_backtrace\+", r.qemu.output)
+    assert matches, "No line numbers"
+    if any(int(m[1]) < 5 or int(m[1]) > 50 for m in matches):
+        assert_equal("\n".join(m[0] for m in matches),
+                     "Line numbers between 5 and 50")
+
+run_tests()
diff --git a/kern/kdebug.c b/kern/kdebug.c
index 9547143..a573a6c 100644
--- a/kern/kdebug.c
+++ b/kern/kdebug.c
@@ -179,6 +179,9 @@ debuginfo_eip(uintptr_t addr, struct Eipdebuginfo *info)
 	//	Look at the STABS documentation and <inc/stab.h> to find
 	//	which one.
 	// Your code here.
+		stab_binsearch(stabs, &lline, &rline, N_SLINE, addr);
+		if (lline <= rline) info->eip_line = lline - lfun;
+		else return -1;
 
 
 	// Search backwards from the line number for the relevant filename
diff --git a/kern/mergedep.pl b/kern/mergedep.pl
new file mode 100644
index 0000000..1730d53
--- /dev/null
+++ b/kern/mergedep.pl
@@ -0,0 +1,86 @@
+#!/usr/bin/perl
+# Copyright 2003 Bryan Ford
+# Distributed under the GNU General Public License.
+#
+# Usage: mergedep <main-depfile> [<new-depfiles> ...]
+#
+# This script merges the contents of all <new-depfiles> specified
+# on the command line into the single file <main-depfile>,
+# which may or may not previously exist.
+# Dependencies in the <new-depfiles> will override
+# any existing dependencies for the same targets in <main-depfile>.
+# The <new-depfiles> are deleted after <main-depfile> is updated.
+#
+# The <new-depfiles> are typically generated by GCC with the -MD option,
+# and the <main-depfile> is typically included from a Makefile,
+# as shown here for GNU 'make':
+#
+#	.deps: $(wildcard *.d)
+#		perl mergedep $@ $^
+#	-include .deps
+#
+# This script properly handles multiple dependencies per <new-depfile>,
+# including dependencies having no target,
+# so it is compatible with GCC3's -MP option.
+#
+
+sub readdeps {
+	my $filename = shift;
+
+	open(DEPFILE, $filename) or return 0;
+	while (<DEPFILE>) {
+		if (/([^:]*):([^\\:]*)([\\]?)$/) {
+			my $target = $1;
+			my $deplines = $2;
+			my $slash = $3;
+			while ($slash ne '') {
+				$_ = <DEPFILE>;
+				defined($_) or die
+					"Unterminated dependency in $filename";
+				/(^[ \t][^\\]*)([\\]?)$/ or die
+					"Bad continuation line in $filename";
+				$deplines = "$deplines\\\n$1";
+				$slash = $2;
+			}
+			#print "DEPENDENCY [[$target]]: [[$deplines]]\n";
+			$dephash{$target} = $deplines;
+		} elsif (/^[#]?[ \t]*$/) {
+			# ignore blank lines and comments
+		} else {
+			die "Bad dependency line in $filename: $_";
+		}
+	}
+	close DEPFILE;
+	return 1;
+}
+
+
+if ($#ARGV < 0) {
+	print "Usage: mergedep <main-depfile> [<new-depfiles> ..]\n";
+	exit(1);
+}
+
+%dephash = ();
+
+# Read the main dependency file
+$maindeps = $ARGV[0];
+readdeps($maindeps);
+
+# Read and merge in the new dependency files
+foreach $i (1 .. $#ARGV) {
+	readdeps($ARGV[$i]) or die "Can't open $ARGV[$i]";
+}
+
+# Update the main dependency file
+open(DEPFILE, ">$maindeps.tmp") or die "Can't open output file $maindeps.tmp";
+foreach $target (keys %dephash) {
+	print DEPFILE "$target:$dephash{$target}";
+}
+close DEPFILE;
+rename("$maindeps.tmp", "$maindeps") or die "Can't overwrite $maindeps";
+
+# Finally, delete the new dependency files
+foreach $i (1 .. $#ARGV) {
+	unlink($ARGV[$i]) or print "Error removing $ARGV[$i]\n";
+}
+
diff --git a/kern/monitor.c b/kern/monitor.c
index e137e92..2c6f8fb 100644
--- a/kern/monitor.c
+++ b/kern/monitor.c
@@ -10,10 +10,17 @@
 #include <kern/console.h>
 #include <kern/monitor.h>
 #include <kern/kdebug.h>
+#include <kern/pmap.h>
 
-#define CMDBUF_SIZE	80	// enough for one VGA text line
 
+#define CMDBUF_SIZE	80	// enough for one VGA text line
 
+int
+mon_pgmap(int argc, char **argv, struct Trapframe *tf);
+ int
+mon_memdump(int argc, char **argv, struct Trapframe *tf);
+ int
+mon_pgperm(int argc, char **argv, struct Trapframe *tf);
 struct Command {
 	const char *name;
 	const char *desc;
@@ -24,6 +31,9 @@ struct Command {
 static struct Command commands[] = {
 	{ "help", "Display this list of commands", mon_help },
 	{ "kerninfo", "Display information about the kernel", mon_kerninfo },
+	{ "pgmap", "Display the physical page mappings", mon_pgmap },
+	{ "pgperm", "set, clear, or change the permissions", mon_pgperm },
+	{ "memdump", "Dump the contents of a range of memory", mon_memdump },
 };
 
 /***** Implementations of basic kernel monitor commands *****/
@@ -57,10 +67,115 @@ mon_kerninfo(int argc, char **argv, struct Trapframe *tf)
 int
 mon_backtrace(int argc, char **argv, struct Trapframe *tf)
 {
-	// Your code here.
+	int *ebp, eip, *old_ebp;
+	int ary[5]={};
+
+	cprintf("Stack backtrace:\n");
+	
+	ebp=(int *)read_ebp();
+	while((int)ebp!=0)
+	{
+		old_ebp=(int *)*(ebp);
+		eip=*(ebp+1);
+		for(int i=0;i<5;++i)
+		{
+			int j=i+2;
+			ary[i]=*(ebp+j);
+		}
+		struct Eipdebuginfo eip_info;
+		debuginfo_eip((uintptr_t)eip, &eip_info);
+		cprintf("\033[16ebp %08x eip %08x args %08x %08x %08x %08x %08x\n",ebp,eip,ary[0],ary[1],ary[2],ary[3],ary[4]);
+		cprintf("\033[28	%s:%d:", eip_info.eip_file, eip_info.eip_line);
+		cprintf("\033[3a %.*s+%d\n", eip_info.eip_fn_namelen, eip_info.eip_fn_name, eip - eip_info.eip_fn_addr);
+		ebp=old_ebp;
+	}
+	
+	return 0;
+}
+
+
+
+
+    int
+mon_pgmap(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t va1, va2, va;
+    struct PageInfo *pg;
+	pte_t *pte;
+    if (argc != 3) {
+	cprintf("Usage: pgmap va1 va2\n Display physical memory mapping from virtual memory va1 to va2\nva1 and va2 are hex\n");
 	return 0;
+    }
+    else {
+	for (va1 = strtol(argv[1], 0, 16), va2 = strtol(argv[2], 0, 16); va1 < va2; va1 += PGSIZE) {
+	    va = va1 & ~0xfff;
+	    pg = page_lookup(kern_pgdir, (void*)va, 0);
+		pte = pgdir_walk(kern_pgdir, (void* )va,0);
+	    if (pg){
+		cprintf("[%x, %x) ---> [%x, %x)    ", va, va + PGSIZE, page2pa(pg), page2pa(pg) + PGSIZE);
+		    if(*pte & PTE_U)
+			cprintf("user: ");
+		   else 
+			cprintf("kernel: ");
+
+		   if(*pte &PTE_W)
+			cprintf("read/write ");
+		   else 
+			cprintf("read only ");
+		}else
+		cprintf("[%x, %x) ---> NULL    ", va, va + PGSIZE);
+
+		cprintf("\n");                                                                                       
+	}
+    }
+    return 0;
+}
+
+
+    int
+mon_pgperm(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t va, perm;
+    if (argc != 4) {
+		cprintf("Usage: pgperm +/-/= perm va\nset perm of page which contains va, va is hex\n");
+		return 0;
+    }
+    else {
+		va = strtol(argv[3], 0, 16);
+		perm = strtol(argv[2], 0, 16);
+		pte_t *pte = pgdir_walk(kern_pgdir, (void*)va, 0);
+		if (!pte) {
+			cprintf("0x%x is not mapped\n", va);
+		}
+		else {
+			if (argv[1][0] == '+') *pte |= perm;
+			if (argv[1][0] == '0') *pte &= ~perm;
+			if (argv[1][0] == '=') *pte = PTE_ADDR(*pte) | perm;
+		}
+    }
+    return 0;
 }
 
+    int
+mon_memdump(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t a1, a2, a;
+    struct PageInfo *pg;
+    if (argc != 4) {
+	cprintf("Usage: memdump p/v a1 a2\n Dump memory content via virtual or physical address\na1 and a2 are hex\n");
+	return 0;
+    }
+    else {
+	a1 = strtol(argv[2], 0, 16), a2 = strtol(argv[3], 0, 16);
+	if (argv[1][0] == 'p') a1 = (int)KADDR(a1), a2 = (int)KADDR(a2);
+	for (a = a1; a < a2 && a >= KERNBASE; a += 4) {
+	    if (!((a - a1) & 0xf)) cprintf("\n%x:\t", a);
+	    cprintf(" %x", *(int*)(a));
+	}
+	cprintf("\n");
+    }
+    return 0;
+}
 
 
 /***** Kernel monitor command interpreter *****/
diff --git a/kern/monitor.c~ b/kern/monitor.c~
new file mode 100644
index 0000000..2c6f8fb
--- /dev/null
+++ b/kern/monitor.c~
@@ -0,0 +1,240 @@
+// Simple command-line kernel monitor useful for
+// controlling the kernel and exploring the system interactively.
+
+#include <inc/stdio.h>
+#include <inc/string.h>
+#include <inc/memlayout.h>
+#include <inc/assert.h>
+#include <inc/x86.h>
+
+#include <kern/console.h>
+#include <kern/monitor.h>
+#include <kern/kdebug.h>
+#include <kern/pmap.h>
+
+
+#define CMDBUF_SIZE	80	// enough for one VGA text line
+
+int
+mon_pgmap(int argc, char **argv, struct Trapframe *tf);
+ int
+mon_memdump(int argc, char **argv, struct Trapframe *tf);
+ int
+mon_pgperm(int argc, char **argv, struct Trapframe *tf);
+struct Command {
+	const char *name;
+	const char *desc;
+	// return -1 to force monitor to exit
+	int (*func)(int argc, char** argv, struct Trapframe* tf);
+};
+
+static struct Command commands[] = {
+	{ "help", "Display this list of commands", mon_help },
+	{ "kerninfo", "Display information about the kernel", mon_kerninfo },
+	{ "pgmap", "Display the physical page mappings", mon_pgmap },
+	{ "pgperm", "set, clear, or change the permissions", mon_pgperm },
+	{ "memdump", "Dump the contents of a range of memory", mon_memdump },
+};
+
+/***** Implementations of basic kernel monitor commands *****/
+
+int
+mon_help(int argc, char **argv, struct Trapframe *tf)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(commands); i++)
+		cprintf("%s - %s\n", commands[i].name, commands[i].desc);
+	return 0;
+}
+
+int
+mon_kerninfo(int argc, char **argv, struct Trapframe *tf)
+{
+	extern char _start[], entry[], etext[], edata[], end[];
+
+	cprintf("Special kernel symbols:\n");
+	cprintf("  _start                  %08x (phys)\n", _start);
+	cprintf("  entry  %08x (virt)  %08x (phys)\n", entry, entry - KERNBASE);
+	cprintf("  etext  %08x (virt)  %08x (phys)\n", etext, etext - KERNBASE);
+	cprintf("  edata  %08x (virt)  %08x (phys)\n", edata, edata - KERNBASE);
+	cprintf("  end    %08x (virt)  %08x (phys)\n", end, end - KERNBASE);
+	cprintf("Kernel executable memory footprint: %dKB\n",
+		ROUNDUP(end - entry, 1024) / 1024);
+	return 0;
+}
+
+int
+mon_backtrace(int argc, char **argv, struct Trapframe *tf)
+{
+	int *ebp, eip, *old_ebp;
+	int ary[5]={};
+
+	cprintf("Stack backtrace:\n");
+	
+	ebp=(int *)read_ebp();
+	while((int)ebp!=0)
+	{
+		old_ebp=(int *)*(ebp);
+		eip=*(ebp+1);
+		for(int i=0;i<5;++i)
+		{
+			int j=i+2;
+			ary[i]=*(ebp+j);
+		}
+		struct Eipdebuginfo eip_info;
+		debuginfo_eip((uintptr_t)eip, &eip_info);
+		cprintf("\033[16ebp %08x eip %08x args %08x %08x %08x %08x %08x\n",ebp,eip,ary[0],ary[1],ary[2],ary[3],ary[4]);
+		cprintf("\033[28	%s:%d:", eip_info.eip_file, eip_info.eip_line);
+		cprintf("\033[3a %.*s+%d\n", eip_info.eip_fn_namelen, eip_info.eip_fn_name, eip - eip_info.eip_fn_addr);
+		ebp=old_ebp;
+	}
+	
+	return 0;
+}
+
+
+
+
+    int
+mon_pgmap(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t va1, va2, va;
+    struct PageInfo *pg;
+	pte_t *pte;
+    if (argc != 3) {
+	cprintf("Usage: pgmap va1 va2\n Display physical memory mapping from virtual memory va1 to va2\nva1 and va2 are hex\n");
+	return 0;
+    }
+    else {
+	for (va1 = strtol(argv[1], 0, 16), va2 = strtol(argv[2], 0, 16); va1 < va2; va1 += PGSIZE) {
+	    va = va1 & ~0xfff;
+	    pg = page_lookup(kern_pgdir, (void*)va, 0);
+		pte = pgdir_walk(kern_pgdir, (void* )va,0);
+	    if (pg){
+		cprintf("[%x, %x) ---> [%x, %x)    ", va, va + PGSIZE, page2pa(pg), page2pa(pg) + PGSIZE);
+		    if(*pte & PTE_U)
+			cprintf("user: ");
+		   else 
+			cprintf("kernel: ");
+
+		   if(*pte &PTE_W)
+			cprintf("read/write ");
+		   else 
+			cprintf("read only ");
+		}else
+		cprintf("[%x, %x) ---> NULL    ", va, va + PGSIZE);
+
+		cprintf("\n");                                                                                       
+	}
+    }
+    return 0;
+}
+
+
+    int
+mon_pgperm(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t va, perm;
+    if (argc != 4) {
+		cprintf("Usage: pgperm +/-/= perm va\nset perm of page which contains va, va is hex\n");
+		return 0;
+    }
+    else {
+		va = strtol(argv[3], 0, 16);
+		perm = strtol(argv[2], 0, 16);
+		pte_t *pte = pgdir_walk(kern_pgdir, (void*)va, 0);
+		if (!pte) {
+			cprintf("0x%x is not mapped\n", va);
+		}
+		else {
+			if (argv[1][0] == '+') *pte |= perm;
+			if (argv[1][0] == '0') *pte &= ~perm;
+			if (argv[1][0] == '=') *pte = PTE_ADDR(*pte) | perm;
+		}
+    }
+    return 0;
+}
+
+    int
+mon_memdump(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t a1, a2, a;
+    struct PageInfo *pg;
+    if (argc != 4) {
+	cprintf("Usage: memdump p/v a1 a2\n Dump memory content via virtual or physical address\na1 and a2 are hex\n");
+	return 0;
+    }
+    else {
+	a1 = strtol(argv[2], 0, 16), a2 = strtol(argv[3], 0, 16);
+	if (argv[1][0] == 'p') a1 = (int)KADDR(a1), a2 = (int)KADDR(a2);
+	for (a = a1; a < a2 && a >= KERNBASE; a += 4) {
+	    if (!((a - a1) & 0xf)) cprintf("\n%x:\t", a);
+	    cprintf(" %x", *(int*)(a));
+	}
+	cprintf("\n");
+    }
+    return 0;
+}
+
+
+/***** Kernel monitor command interpreter *****/
+
+#define WHITESPACE "\t\r\n "
+#define MAXARGS 16
+
+static int
+runcmd(char *buf, struct Trapframe *tf)
+{
+	int argc;
+	char *argv[MAXARGS];
+	int i;
+
+	// Parse the command buffer into whitespace-separated arguments
+	argc = 0;
+	argv[argc] = 0;
+	while (1) {
+		// gobble whitespace
+		while (*buf && strchr(WHITESPACE, *buf))
+			*buf++ = 0;
+		if (*buf == 0)
+			break;
+
+		// save and scan past next arg
+		if (argc == MAXARGS-1) {
+			cprintf("Too many arguments (max %d)\n", MAXARGS);
+			return 0;
+		}
+		argv[argc++] = buf;
+		while (*buf && !strchr(WHITESPACE, *buf))
+			buf++;
+	}
+	argv[argc] = 0;
+
+	// Lookup and invoke the command
+	if (argc == 0)
+		return 0;
+	for (i = 0; i < ARRAY_SIZE(commands); i++) {
+		if (strcmp(argv[0], commands[i].name) == 0)
+			return commands[i].func(argc, argv, tf);
+	}
+	cprintf("Unknown command '%s'\n", argv[0]);
+	return 0;
+}
+
+void
+monitor(struct Trapframe *tf)
+{
+	char *buf;
+
+	cprintf("Welcome to the JOS kernel monitor!\n");
+	cprintf("Type 'help' for a list of commands.\n");
+
+
+	while (1) {
+		buf = readline("K> ");
+		if (buf != NULL)
+			if (runcmd(buf, tf) < 0)
+				break;
+	}
+}
diff --git a/kern/pmap.c b/kern/pmap.c
index 9a10e6e..f6e2cfb 100644
--- a/kern/pmap.c
+++ b/kern/pmap.c
@@ -18,7 +18,6 @@ pde_t *kern_pgdir;		// Kernel's initial page directory
 struct PageInfo *pages;		// Physical page state array
 static struct PageInfo *page_free_list;	// Free list of physical pages
 
-
 // --------------------------------------------------------------
 // Detect machine's physical memory setup.
 // --------------------------------------------------------------
@@ -86,7 +85,6 @@ boot_alloc(uint32_t n)
 {
 	static char *nextfree;	// virtual address of next byte of free memory
 	char *result;
-
 	// Initialize nextfree if this is the first time.
 	// 'end' is a magic symbol automatically generated by the linker,
 	// which points to the end of the kernel's bss segment:
@@ -100,10 +98,17 @@ boot_alloc(uint32_t n)
 	// Allocate a chunk large enough to hold 'n' bytes, then update
 	// nextfree.  Make sure nextfree is kept aligned
 	// to a multiple of PGSIZE.
-	//
 	// LAB 2: Your code here.
-
-	return NULL;
+	if (n == 0) return (void*)nextfree;
+	n = ROUNDUP(n, PGSIZE);
+	if (PADDR(nextfree + n) > npages * PGSIZE)
+	{
+		panic("kern/pmap.c: boot_alloc()");
+		return NULL;
+	}
+	result = nextfree;
+	nextfree += n;
+	return result;
 }
 
 // Set up a two-level page table:
@@ -125,7 +130,7 @@ mem_init(void)
 	i386_detect_memory();
 
 	// Remove this line when you're ready to test this function.
-	panic("mem_init: This function is not finished\n");
+	//panic("mem_init: This function is not finished\n");
 
 	//////////////////////////////////////////////////////////////////////
 	// create initial page directory.
@@ -148,7 +153,8 @@ mem_init(void)
 	// array.  'npages' is the number of physical pages in memory.  Use memset
 	// to initialize all fields of each struct PageInfo to 0.
 	// Your code goes here:
-
+	pages = (struct PageInfo*)boot_alloc(npages * sizeof(struct PageInfo));
+	memset(pages, 0, npages * sizeof(struct PageInfo));
 
 	//////////////////////////////////////////////////////////////////////
 	// Now that we've allocated the initial kernel data structures, we set
@@ -157,6 +163,7 @@ mem_init(void)
 	// particular, we can now map memory using boot_map_region
 	// or page_insert
 	page_init();
+	
 
 	check_page_free_list(1);
 	check_page_alloc();
@@ -172,6 +179,8 @@ mem_init(void)
 	//      (ie. perm = PTE_U | PTE_P)
 	//    - pages itself -- kernel RW, user NONE
 	// Your code goes here:
+    	boot_map_region(kern_pgdir, UPAGES, ROUNDUP(sizeof(struct PageInfo)* npages, PGSIZE), PADDR(pages), PTE_U);
+
 
 	//////////////////////////////////////////////////////////////////////
 	// Use the physical memory that 'bootstack' refers to as the kernel
@@ -184,6 +193,7 @@ mem_init(void)
 	//       overwrite memory.  Known as a "guard page".
 	//     Permissions: kernel RW, user NONE
 	// Your code goes here:
+	 boot_map_region(kern_pgdir, KSTACKTOP - KSTKSIZE, ROUNDUP(KSTKSIZE, PGSIZE), PADDR(bootstack), PTE_W);
 
 	//////////////////////////////////////////////////////////////////////
 	// Map all of physical memory at KERNBASE.
@@ -193,6 +203,8 @@ mem_init(void)
 	// we just set up the mapping anyway.
 	// Permissions: kernel RW, user NONE
 	// Your code goes here:
+    	boot_map_region(kern_pgdir, (uintptr_t)KERNBASE , -KERNBASE, (physaddr_t)0, PTE_W);
+
 
 	// Check that the initial page directory has been set up correctly.
 	check_kern_pgdir();
@@ -252,11 +264,15 @@ page_init(void)
 	// NB: DO NOT actually touch the physical memory corresponding to
 	// free pages!
 	size_t i;
-	for (i = 0; i < npages; i++) {
-		pages[i].pp_ref = 0;
-		pages[i].pp_link = page_free_list;
-		page_free_list = &pages[i];
-	}
+    	assert(page_free_list == 0);
+    	unsigned used_top = PADDR(boot_alloc(0));
+    	for (i = 0; i < npages; i++) {
+		if (i == 0 || (page2pa(&pages[i]) >= IOPHYSMEM && page2pa(&pages[i]) < used_top))
+	   	continue;
+	pages[i].pp_ref = 0;
+	pages[i].pp_link = page_free_list;
+	page_free_list = &pages[i];
+    	}
 }
 
 //
@@ -275,7 +291,14 @@ struct PageInfo *
 page_alloc(int alloc_flags)
 {
 	// Fill this function in
-	return 0;
+	if (page_free_list == NULL) return NULL;
+    	struct PageInfo* ret = page_free_list;
+   	page_free_list = ret->pp_link;
+    	if (alloc_flags & ALLOC_ZERO) 
+		memset(page2kva(ret), 0, PGSIZE);
+	ret->pp_link = NULL;
+    	return ret;
+
 }
 
 //
@@ -288,8 +311,18 @@ page_free(struct PageInfo *pp)
 	// Fill this function in
 	// Hint: You may want to panic if pp->pp_ref is nonzero or
 	// pp->pp_link is not NULL.
+		
+	if(pp->pp_ref == 0){
+    		pp->pp_link = page_free_list;
+	    	page_free_list = pp;
+	}
+	else
+	{
+		panic("pp->pp_ref is not zero. Wrong call of the page_free!!!");
+	}
 }
 
+
 //
 // Decrement the reference count on a page,
 // freeing it if there are no more refs.
@@ -326,8 +359,15 @@ page_decref(struct PageInfo* pp)
 pte_t *
 pgdir_walk(pde_t *pgdir, const void *va, int create)
 {
-	// Fill this function in
-	return NULL;
+    // Fill this function in
+      if (!(pgdir[PDX(va)] & PTE_P)) {
+	if (!create) return NULL;
+	struct PageInfo *page = page_alloc(ALLOC_ZERO);
+	if (!page) return NULL;
+	page->pp_ref = 1;
+	pgdir[PDX(va)] = page2pa(page) | PTE_P | PTE_U | PTE_W;
+    }
+    return KADDR(PTE_ADDR(pgdir[PDX(va)])) + PTX(va) * sizeof(pte_t*);
 }
 
 //
@@ -341,12 +381,19 @@ pgdir_walk(pde_t *pgdir, const void *va, int create)
 // mapped pages.
 //
 // Hint: the TA solution uses pgdir_walk
+//
 static void
 boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
 {
-	// Fill this function in
+    // Fill this function in
+    int i;
+    for (i = 0; i < size; i += PGSIZE) {
+	pte_t *pte = pgdir_walk(pgdir, (void*)(va + i), 1);
+	if (pte) *pte = (pa + i) | perm | PTE_P;
+    }
 }
 
+
 //
 // Map the physical page 'pp' at virtual address 'va'.
 // The permissions (the low 12 bits) of the page table entry
@@ -376,7 +423,20 @@ int
 page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
 {
 	// Fill this function in
-	return 0;
+	pte_t *pte = pgdir_walk(pgdir, va, 1);
+    	if (pte == NULL) return -E_NO_MEM;
+    	if (*pte & PTE_P) {
+		if (PTE_ADDR(*pte) == page2pa(pp)) {
+		    pp->pp_ref--;
+		    tlb_invalidate(pgdir, va);
+		}
+		else {
+		    page_remove(pgdir, va);
+		}
+    	}
+    	*pte = page2pa(pp) | perm | PTE_P;
+    	pp->pp_ref++;
+    	return 0;
 }
 
 //
@@ -394,13 +454,16 @@ struct PageInfo *
 page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
 {
 	// Fill this function in
-	return NULL;
+    	pte_t *pte = pgdir_walk(pgdir, va, 0);
+   	if (pte_store != NULL) *pte_store = pte;
+    	if (pte == NULL || !(*pte & PTE_P)) return NULL;
+    	return pa2page(PTE_ADDR(*pte));
 }
 
 //
 // Unmaps the physical page at virtual address 'va'.
 // If there is no physical page at that address, silently does nothing.
-//
+// 
 // Details:
 //   - The ref count on the physical page should decrement.
 //   - The physical page should be freed if the refcount reaches 0.
@@ -415,7 +478,14 @@ page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
 void
 page_remove(pde_t *pgdir, void *va)
 {
-	// Fill this function in
+   	// Fill this function in
+    	struct PageInfo *page = page_lookup(pgdir, va, 0);
+    	pte_t *pte = pgdir_walk(pgdir, va, 0);
+    	if (page != NULL) page_decref(page);
+    	if (pte != NULL) {
+		*pte = 0;
+		tlb_invalidate(pgdir, va);
+    	}
 }
 
 //
diff --git a/kern/pmap.c~ b/kern/pmap.c~
new file mode 100644
index 0000000..92e3eb6
--- /dev/null
+++ b/kern/pmap.c~
@@ -0,0 +1,909 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/x86.h>
+#include <inc/mmu.h>
+#include <inc/error.h>
+#include <inc/string.h>
+#include <inc/assert.h>
+
+#include <kern/pmap.h>
+#include <kern/kclock.h>
+
+// These variables are set by i386_detect_memory()
+size_t npages;			// Amount of physical memory (in pages)
+static size_t npages_basemem;	// Amount of base memory (in pages)
+
+// These variables are set in mem_init()
+pde_t *kern_pgdir;		// Kernel's initial page directory
+struct PageInfo *pages;		// Physical page state array
+static struct PageInfo *page_free_list;	// Free list of physical pages
+
+// --------------------------------------------------------------
+// Detect machine's physical memory setup.
+// --------------------------------------------------------------
+
+static int
+nvram_read(int r)
+{
+	return mc146818_read(r) | (mc146818_read(r + 1) << 8);
+}
+
+static void
+i386_detect_memory(void)
+{
+	size_t basemem, extmem, ext16mem, totalmem;
+
+	// Use CMOS calls to measure available base & extended memory.
+	// (CMOS calls return results in kilobytes.)
+	basemem = nvram_read(NVRAM_BASELO);
+	extmem = nvram_read(NVRAM_EXTLO);
+	ext16mem = nvram_read(NVRAM_EXT16LO) * 64;
+
+	// Calculate the number of physical pages available in both base
+	// and extended memory.
+	if (ext16mem)
+		totalmem = 16 * 1024 + ext16mem;
+	else if (extmem)
+		totalmem = 1 * 1024 + extmem;
+	else
+		totalmem = basemem;
+
+	npages = totalmem / (PGSIZE / 1024);
+	npages_basemem = basemem / (PGSIZE / 1024);
+
+	cprintf("Physical memory: %uK available, base = %uK, extended = %uK\n",
+		totalmem, basemem, totalmem - basemem);
+}
+
+
+// --------------------------------------------------------------
+// Set up memory mappings above UTOP.
+// --------------------------------------------------------------
+
+static void boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm);
+static void check_page_free_list(bool only_low_memory);
+static void check_page_alloc(void);
+static void check_kern_pgdir(void);
+static physaddr_t check_va2pa(pde_t *pgdir, uintptr_t va);
+static void check_page(void);
+static void check_page_installed_pgdir(void);
+
+// This simple physical memory allocator is used only while JOS is setting
+// up its virtual memory system.  page_alloc() is the real allocator.
+//
+// If n>0, allocates enough pages of contiguous physical memory to hold 'n'
+// bytes.  Doesn't initialize the memory.  Returns a kernel virtual address.
+//
+// If n==0, returns the address of the next free page without allocating
+// anything.
+//
+// If we're out of memory, boot_alloc should panic.
+// This function may ONLY be used during initialization,
+// before the page_free_list list has been set up.
+static void *
+boot_alloc(uint32_t n)
+{
+	static char *nextfree;	// virtual address of next byte of free memory
+	char *result;
+	// Initialize nextfree if this is the first time.
+	// 'end' is a magic symbol automatically generated by the linker,
+	// which points to the end of the kernel's bss segment:
+	// the first virtual address that the linker did *not* assign
+	// to any kernel code or global variables.
+	if (!nextfree) {
+		extern char end[];
+		nextfree = ROUNDUP((char *) end, PGSIZE);
+	}
+
+	// Allocate a chunk large enough to hold 'n' bytes, then update
+	// nextfree.  Make sure nextfree is kept aligned
+	// to a multiple of PGSIZE.
+	// LAB 2: Your code here.
+	if (n == 0) return (void*)nextfree;
+	n = ROUNDUP(n, PGSIZE);
+	if (PADDR(nextfree + n) > npages * PGSIZE)
+	{
+		panic("kern/pmap.c: boot_alloc()");
+		return NULL;
+	}
+	result = nextfree;
+	nextfree += n;
+	return result;
+}
+
+// Set up a two-level page table:
+//    kern_pgdir is its linear (virtual) address of the root
+//
+// This function only sets up the kernel part of the address space
+// (ie. addresses >= UTOP).  The user part of the address space
+// will be setup later.
+//
+// From UTOP to ULIM, the user is allowed to read but not write.
+// Above ULIM the user cannot read or write.
+void
+mem_init(void)
+{
+	uint32_t cr0;
+	size_t n;
+
+	// Find out how much memory the machine has (npages & npages_basemem).
+	i386_detect_memory();
+
+	// Remove this line when you're ready to test this function.
+	//panic("mem_init: This function is not finished\n");
+
+	//////////////////////////////////////////////////////////////////////
+	// create initial page directory.
+	kern_pgdir = (pde_t *) boot_alloc(PGSIZE);
+	memset(kern_pgdir, 0, PGSIZE);
+
+	//////////////////////////////////////////////////////////////////////
+	// Recursively insert PD in itself as a page table, to form
+	// a virtual page table at virtual address UVPT.
+	// (For now, you don't have understand the greater purpose of the
+	// following line.)
+
+	// Permissions: kernel R, user R
+	kern_pgdir[PDX(UVPT)] = PADDR(kern_pgdir) | PTE_U | PTE_P;
+
+	//////////////////////////////////////////////////////////////////////
+	// Allocate an array of npages 'struct PageInfo's and store it in 'pages'.
+	// The kernel uses this array to keep track of physical pages: for
+	// each physical page, there is a corresponding struct PageInfo in this
+	// array.  'npages' is the number of physical pages in memory.  Use memset
+	// to initialize all fields of each struct PageInfo to 0.
+	// Your code goes here:
+	pages = (struct PageInfo*)boot_alloc(npages * sizeof(struct PageInfo));
+	memset(pages, 0, npages * sizeof(struct PageInfo));
+
+	//////////////////////////////////////////////////////////////////////
+	// Now that we've allocated the initial kernel data structures, we set
+	// up the list of free physical pages. Once we've done so, all further
+	// memory management will go through the page_* functions. In
+	// particular, we can now map memory using boot_map_region
+	// or page_insert
+	page_init();
+	
+
+	check_page_free_list(1);
+	check_page_alloc();
+	check_page();
+
+	//////////////////////////////////////////////////////////////////////
+	// Now we set up virtual memory
+
+	//////////////////////////////////////////////////////////////////////
+	// Map 'pages' read-only by the user at linear address UPAGES
+	// Permissions:
+	//    - the new image at UPAGES -- kernel R, user R
+	//      (ie. perm = PTE_U | PTE_P)
+	//    - pages itself -- kernel RW, user NONE
+	// Your code goes here:
+    	boot_map_region(kern_pgdir, UPAGES, ROUNDUP(sizeof(struct PageInfo)* npages, PGSIZE), PADDR(pages), PTE_U);
+
+
+	//////////////////////////////////////////////////////////////////////
+	// Use the physical memory that 'bootstack' refers to as the kernel
+	// stack.  The kernel stack grows down from virtual address KSTACKTOP.
+	// We consider the entire range from [KSTACKTOP-PTSIZE, KSTACKTOP)
+	// to be the kernel stack, but break this into two pieces:
+	//     * [KSTACKTOP-KSTKSIZE, KSTACKTOP) -- backed by physical memory
+	//     * [KSTACKTOP-PTSIZE, KSTACKTOP-KSTKSIZE) -- not backed; so if
+	//       the kernel overflows its stack, it will fault rather than
+	//       overwrite memory.  Known as a "guard page".
+	//     Permissions: kernel RW, user NONE
+	// Your code goes here:
+	 boot_map_region(kern_pgdir, KSTACKTOP - KSTKSIZE, ROUNDUP(KSTKSIZE, PGSIZE), PADDR(bootstack), PTE_W);
+
+	//////////////////////////////////////////////////////////////////////
+	// Map all of physical memory at KERNBASE.
+	// Ie.  the VA range [KERNBASE, 2^32) should map to
+	//      the PA range [0, 2^32 - KERNBASE)
+	// We might not have 2^32 - KERNBASE bytes of physical memory, but
+	// we just set up the mapping anyway.
+	// Permissions: kernel RW, user NONE
+	// Your code goes here:
+    	boot_map_region(kern_pgdir, (uintptr_t)KERNBASE , (1<<28), (physaddr_t)0, PTE_W);
+
+
+	// Check that the initial page directory has been set up correctly.
+	check_kern_pgdir();
+
+	// Switch from the minimal entry page directory to the full kern_pgdir
+	// page table we just created.	Our instruction pointer should be
+	// somewhere between KERNBASE and KERNBASE+4MB right now, which is
+	// mapped the same way by both page tables.
+	//
+	// If the machine reboots at this point, you've probably set up your
+	// kern_pgdir wrong.
+	lcr3(PADDR(kern_pgdir));
+
+	check_page_free_list(0);
+
+	// entry.S set the really important flags in cr0 (including enabling
+	// paging).  Here we configure the rest of the flags that we care about.
+	cr0 = rcr0();
+	cr0 |= CR0_PE|CR0_PG|CR0_AM|CR0_WP|CR0_NE|CR0_MP;
+	cr0 &= ~(CR0_TS|CR0_EM);
+	lcr0(cr0);
+
+	// Some more checks, only possible after kern_pgdir is installed.
+	check_page_installed_pgdir();
+}
+
+// --------------------------------------------------------------
+// Tracking of physical pages.
+// The 'pages' array has one 'struct PageInfo' entry per physical page.
+// Pages are reference counted, and free pages are kept on a linked list.
+// --------------------------------------------------------------
+
+//
+// Initialize page structure and memory free list.
+// After this is done, NEVER use boot_alloc again.  ONLY use the page
+// allocator functions below to allocate and deallocate physical
+// memory via the page_free_list.
+//
+void
+page_init(void)
+{
+	// The example code here marks all physical pages as free.
+	// However this is not truly the case.  What memory is free?
+	//  1) Mark physical page 0 as in use.
+	//     This way we preserve the real-mode IDT and BIOS structures
+	//     in case we ever need them.  (Currently we don't, but...)
+	//  2) The rest of base memory, [PGSIZE, npages_basemem * PGSIZE)
+	//     is free.
+	//  3) Then comes the IO hole [IOPHYSMEM, EXTPHYSMEM), which must
+	//     never be allocated.
+	//  4) Then extended memory [EXTPHYSMEM, ...).
+	//     Some of it is in use, some is free. Where is the kernel
+	//     in physical memory?  Which pages are already in use for
+	//     page tables and other data structures?
+	//
+	// Change the code to reflect this.
+	// NB: DO NOT actually touch the physical memory corresponding to
+	// free pages!
+	size_t i;
+    	assert(page_free_list == 0);
+    	unsigned used_top = PADDR(boot_alloc(0));
+    	for (i = 0; i < npages; i++) {
+		if (i == 0 || (page2pa(&pages[i]) >= IOPHYSMEM && page2pa(&pages[i]) < used_top))
+	   	continue;
+	pages[i].pp_ref = 0;
+	pages[i].pp_link = page_free_list;
+	page_free_list = &pages[i];
+    	}
+}
+
+//
+// Allocates a physical page.  If (alloc_flags & ALLOC_ZERO), fills the entire
+// returned physical page with '\0' bytes.  Does NOT increment the reference
+// count of the page - the caller must do these if necessary (either explicitly
+// or via page_insert).
+//
+// Be sure to set the pp_link field of the allocated page to NULL so
+// page_free can check for double-free bugs.
+//
+// Returns NULL if out of free memory.
+//
+// Hint: use page2kva and memset
+struct PageInfo *
+page_alloc(int alloc_flags)
+{
+	// Fill this function in
+	if (page_free_list == NULL) return NULL;
+    	struct PageInfo* ret = page_free_list;
+   	page_free_list = ret->pp_link;
+    	if (alloc_flags & ALLOC_ZERO) 
+		memset(page2kva(ret), 0, PGSIZE);
+	ret->pp_link = NULL;
+    	return ret;
+
+}
+
+//
+// Return a page to the free list.
+// (This function should only be called when pp->pp_ref reaches 0.)
+//
+void
+page_free(struct PageInfo *pp)
+{
+	// Fill this function in
+	// Hint: You may want to panic if pp->pp_ref is nonzero or
+	// pp->pp_link is not NULL.
+		
+	if(pp->pp_ref == 0){
+    		pp->pp_link = page_free_list;
+	    	page_free_list = pp;
+	}
+	else
+	{
+		panic("pp->pp_ref is not zero. Wrong call of the page_free!!!");
+	}
+}
+
+
+//
+// Decrement the reference count on a page,
+// freeing it if there are no more refs.
+//
+void
+page_decref(struct PageInfo* pp)
+{
+	if (--pp->pp_ref == 0)
+		page_free(pp);
+}
+
+// Given 'pgdir', a pointer to a page directory, pgdir_walk returns
+// a pointer to the page table entry (PTE) for linear address 'va'.
+// This requires walking the two-level page table structure.
+//
+// The relevant page table page might not exist yet.
+// If this is true, and create == false, then pgdir_walk returns NULL.
+// Otherwise, pgdir_walk allocates a new page table page with page_alloc.
+//    - If the allocation fails, pgdir_walk returns NULL.
+//    - Otherwise, the new page's reference count is incremented,
+//	the page is cleared,
+//	and pgdir_walk returns a pointer into the new page table page.
+//
+// Hint 1: you can turn a PageInfo * into the physical address of the
+// page it refers to with page2pa() from kern/pmap.h.
+//
+// Hint 2: the x86 MMU checks permission bits in both the page directory
+// and the page table, so it's safe to leave permissions in the page
+// directory more permissive than strictly necessary.
+//
+// Hint 3: look at inc/mmu.h for useful macros that mainipulate page
+// table and page directory entries.
+//
+pte_t *
+pgdir_walk(pde_t *pgdir, const void *va, int create)
+{
+    // Fill this function in
+      if (!(pgdir[PDX(va)] & PTE_P)) {
+	if (!create) return NULL;
+	struct PageInfo *page = page_alloc(ALLOC_ZERO);
+	if (!page) return NULL;
+	page->pp_ref = 1;
+	pgdir[PDX(va)] = page2pa(page) | PTE_P | PTE_U | PTE_W;
+    }
+    return KADDR(PTE_ADDR(pgdir[PDX(va)])) + PTX(va) * sizeof(pte_t*);
+}
+
+//
+// Map [va, va+size) of virtual address space to physical [pa, pa+size)
+// in the page table rooted at pgdir.  Size is a multiple of PGSIZE, and
+// va and pa are both page-aligned.
+// Use permission bits perm|PTE_P for the entries.
+//
+// This function is only intended to set up the ``static'' mappings
+// above UTOP. As such, it should *not* change the pp_ref field on the
+// mapped pages.
+//
+// Hint: the TA solution uses pgdir_walk
+//
+static void
+boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
+{
+    // Fill this function in
+    int i;
+    for (i = 0; i < size; i += PGSIZE) {
+	pte_t *pte = pgdir_walk(pgdir, (void*)(va + i), 1);
+	if (pte) *pte = (pa + i) | perm | PTE_P;
+    }
+}
+
+
+//
+// Map the physical page 'pp' at virtual address 'va'.
+// The permissions (the low 12 bits) of the page table entry
+// should be set to 'perm|PTE_P'.
+//
+// Requirements
+//   - If there is already a page mapped at 'va', it should be page_remove()d.
+//   - If necessary, on demand, a page table should be allocated and inserted
+//     into 'pgdir'.
+//   - pp->pp_ref should be incremented if the insertion succeeds.
+//   - The TLB must be invalidated if a page was formerly present at 'va'.
+//
+// Corner-case hint: Make sure to consider what happens when the same
+// pp is re-inserted at the same virtual address in the same pgdir.
+// However, try not to distinguish this case in your code, as this
+// frequently leads to subtle bugs; there's an elegant way to handle
+// everything in one code path.
+//
+// RETURNS:
+//   0 on success
+//   -E_NO_MEM, if page table couldn't be allocated
+//
+// Hint: The TA solution is implemented using pgdir_walk, page_remove,
+// and page2pa.
+//
+int
+page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
+{
+	// Fill this function in
+	pte_t *pte = pgdir_walk(pgdir, va, 1);
+    	if (pte == NULL) return -E_NO_MEM;
+    	if (*pte & PTE_P) {
+		if (PTE_ADDR(*pte) == page2pa(pp)) {
+		    pp->pp_ref--;
+		    tlb_invalidate(pgdir, va);
+		}
+		else {
+		    page_remove(pgdir, va);
+		}
+    	}
+    	*pte = page2pa(pp) | perm | PTE_P;
+    	pp->pp_ref++;
+    	return 0;
+}
+
+//
+// Return the page mapped at virtual address 'va'.
+// If pte_store is not zero, then we store in it the address
+// of the pte for this page.  This is used by page_remove and
+// can be used to verify page permissions for syscall arguments,
+// but should not be used by most callers.
+//
+// Return NULL if there is no page mapped at va.
+//
+// Hint: the TA solution uses pgdir_walk and pa2page.
+//
+struct PageInfo *
+page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
+{
+	// Fill this function in
+    	pte_t *pte = pgdir_walk(pgdir, va, 0);
+   	if (pte_store != NULL) *pte_store = pte;
+    	if (pte == NULL || !(*pte & PTE_P)) return NULL;
+    	return pa2page(PTE_ADDR(*pte));
+}
+
+//
+// Unmaps the physical page at virtual address 'va'.
+// If there is no physical page at that address, silently does nothing.
+// 
+// Details:
+//   - The ref count on the physical page should decrement.
+//   - The physical page should be freed if the refcount reaches 0.
+//   - The pg table entry corresponding to 'va' should be set to 0.
+//     (if such a PTE exists)
+//   - The TLB must be invalidated if you remove an entry from
+//     the page table.
+//
+// Hint: The TA solution is implemented using page_lookup,
+// 	tlb_invalidate, and page_decref.
+//
+void
+page_remove(pde_t *pgdir, void *va)
+{
+   	// Fill this function in
+    	struct PageInfo *page = page_lookup(pgdir, va, 0);
+    	pte_t *pte = pgdir_walk(pgdir, va, 0);
+    	if (page != NULL) page_decref(page);
+    	if (pte != NULL) {
+		*pte = 0;
+		tlb_invalidate(pgdir, va);
+    	}
+}
+
+//
+// Invalidate a TLB entry, but only if the page tables being
+// edited are the ones currently in use by the processor.
+//
+void
+tlb_invalidate(pde_t *pgdir, void *va)
+{
+	// Flush the entry only if we're modifying the current address space.
+	// For now, there is only one address space, so always invalidate.
+	invlpg(va);
+}
+
+
+// --------------------------------------------------------------
+// Checking functions.
+// --------------------------------------------------------------
+
+//
+// Check that the pages on the page_free_list are reasonable.
+//
+static void
+check_page_free_list(bool only_low_memory)
+{
+	struct PageInfo *pp;
+	unsigned pdx_limit = only_low_memory ? 1 : NPDENTRIES;
+	int nfree_basemem = 0, nfree_extmem = 0;
+	char *first_free_page;
+
+	if (!page_free_list)
+		panic("'page_free_list' is a null pointer!");
+
+	if (only_low_memory) {
+		// Move pages with lower addresses first in the free
+		// list, since entry_pgdir does not map all pages.
+		struct PageInfo *pp1, *pp2;
+		struct PageInfo **tp[2] = { &pp1, &pp2 };
+		for (pp = page_free_list; pp; pp = pp->pp_link) {
+			int pagetype = PDX(page2pa(pp)) >= pdx_limit;
+			*tp[pagetype] = pp;
+			tp[pagetype] = &pp->pp_link;
+		}
+		*tp[1] = 0;
+		*tp[0] = pp2;
+		page_free_list = pp1;
+	}
+
+	// if there's a page that shouldn't be on the free list,
+	// try to make sure it eventually causes trouble.
+	for (pp = page_free_list; pp; pp = pp->pp_link)
+		if (PDX(page2pa(pp)) < pdx_limit)
+			memset(page2kva(pp), 0x97, 128);
+
+	first_free_page = (char *) boot_alloc(0);
+	for (pp = page_free_list; pp; pp = pp->pp_link) {
+		// check that we didn't corrupt the free list itself
+		assert(pp >= pages);
+		assert(pp < pages + npages);
+		assert(((char *) pp - (char *) pages) % sizeof(*pp) == 0);
+
+		// check a few pages that shouldn't be on the free list
+		assert(page2pa(pp) != 0);
+		assert(page2pa(pp) != IOPHYSMEM);
+		assert(page2pa(pp) != EXTPHYSMEM - PGSIZE);
+		assert(page2pa(pp) != EXTPHYSMEM);
+		assert(page2pa(pp) < EXTPHYSMEM || (char *) page2kva(pp) >= first_free_page);
+
+		if (page2pa(pp) < EXTPHYSMEM)
+			++nfree_basemem;
+		else
+			++nfree_extmem;
+	}
+
+	assert(nfree_basemem > 0);
+	assert(nfree_extmem > 0);
+}
+
+//
+// Check the physical page allocator (page_alloc(), page_free(),
+// and page_init()).
+//
+static void
+check_page_alloc(void)
+{
+	struct PageInfo *pp, *pp0, *pp1, *pp2;
+	int nfree;
+	struct PageInfo *fl;
+	char *c;
+	int i;
+
+	if (!pages)
+		panic("'pages' is a null pointer!");
+
+	// check number of free pages
+	for (pp = page_free_list, nfree = 0; pp; pp = pp->pp_link)
+		++nfree;
+
+	// should be able to allocate three pages
+	pp0 = pp1 = pp2 = 0;
+	assert((pp0 = page_alloc(0)));
+	assert((pp1 = page_alloc(0)));
+	assert((pp2 = page_alloc(0)));
+
+	assert(pp0);
+	assert(pp1 && pp1 != pp0);
+	assert(pp2 && pp2 != pp1 && pp2 != pp0);
+	assert(page2pa(pp0) < npages*PGSIZE);
+	assert(page2pa(pp1) < npages*PGSIZE);
+	assert(page2pa(pp2) < npages*PGSIZE);
+
+	// temporarily steal the rest of the free pages
+	fl = page_free_list;
+	page_free_list = 0;
+
+	// should be no free memory
+	assert(!page_alloc(0));
+
+	// free and re-allocate?
+	page_free(pp0);
+	page_free(pp1);
+	page_free(pp2);
+	pp0 = pp1 = pp2 = 0;
+	assert((pp0 = page_alloc(0)));
+	assert((pp1 = page_alloc(0)));
+	assert((pp2 = page_alloc(0)));
+	assert(pp0);
+	assert(pp1 && pp1 != pp0);
+	assert(pp2 && pp2 != pp1 && pp2 != pp0);
+	assert(!page_alloc(0));
+
+	// test flags
+	memset(page2kva(pp0), 1, PGSIZE);
+	page_free(pp0);
+	assert((pp = page_alloc(ALLOC_ZERO)));
+	assert(pp && pp0 == pp);
+	c = page2kva(pp);
+	for (i = 0; i < PGSIZE; i++)
+		assert(c[i] == 0);
+
+	// give free list back
+	page_free_list = fl;
+
+	// free the pages we took
+	page_free(pp0);
+	page_free(pp1);
+	page_free(pp2);
+
+	// number of free pages should be the same
+	for (pp = page_free_list; pp; pp = pp->pp_link)
+		--nfree;
+	assert(nfree == 0);
+
+	cprintf("check_page_alloc() succeeded!\n");
+}
+
+//
+// Checks that the kernel part of virtual address space
+// has been setup roughly correctly (by mem_init()).
+//
+// This function doesn't test every corner case,
+// but it is a pretty good sanity check.
+//
+
+static void
+check_kern_pgdir(void)
+{
+	uint32_t i, n;
+	pde_t *pgdir;
+
+	pgdir = kern_pgdir;
+
+	// check pages array
+	n = ROUNDUP(npages*sizeof(struct PageInfo), PGSIZE);
+	for (i = 0; i < n; i += PGSIZE)
+		assert(check_va2pa(pgdir, UPAGES + i) == PADDR(pages) + i);
+
+
+	// check phys mem
+	for (i = 0; i < npages * PGSIZE; i += PGSIZE)
+		assert(check_va2pa(pgdir, KERNBASE + i) == i);
+
+	// check kernel stack
+	for (i = 0; i < KSTKSIZE; i += PGSIZE)
+		assert(check_va2pa(pgdir, KSTACKTOP - KSTKSIZE + i) == PADDR(bootstack) + i);
+	assert(check_va2pa(pgdir, KSTACKTOP - PTSIZE) == ~0);
+
+	// check PDE permissions
+	for (i = 0; i < NPDENTRIES; i++) {
+		switch (i) {
+		case PDX(UVPT):
+		case PDX(KSTACKTOP-1):
+		case PDX(UPAGES):
+			assert(pgdir[i] & PTE_P);
+			break;
+		default:
+			if (i >= PDX(KERNBASE)) {
+				assert(pgdir[i] & PTE_P);
+				assert(pgdir[i] & PTE_W);
+			} else
+				assert(pgdir[i] == 0);
+			break;
+		}
+	}
+	cprintf("check_kern_pgdir() succeeded!\n");
+}
+
+// This function returns the physical address of the page containing 'va',
+// defined by the page directory 'pgdir'.  The hardware normally performs
+// this functionality for us!  We define our own version to help check
+// the check_kern_pgdir() function; it shouldn't be used elsewhere.
+
+static physaddr_t
+check_va2pa(pde_t *pgdir, uintptr_t va)
+{
+	pte_t *p;
+
+	pgdir = &pgdir[PDX(va)];
+	if (!(*pgdir & PTE_P))
+		return ~0;
+	p = (pte_t*) KADDR(PTE_ADDR(*pgdir));
+	if (!(p[PTX(va)] & PTE_P))
+		return ~0;
+	return PTE_ADDR(p[PTX(va)]);
+}
+
+
+// check page_insert, page_remove, &c
+static void
+check_page(void)
+{
+	struct PageInfo *pp, *pp0, *pp1, *pp2;
+	struct PageInfo *fl;
+	pte_t *ptep, *ptep1;
+	void *va;
+	int i;
+	extern pde_t entry_pgdir[];
+
+	// should be able to allocate three pages
+	pp0 = pp1 = pp2 = 0;
+	assert((pp0 = page_alloc(0)));
+	assert((pp1 = page_alloc(0)));
+	assert((pp2 = page_alloc(0)));
+
+	assert(pp0);
+	assert(pp1 && pp1 != pp0);
+	assert(pp2 && pp2 != pp1 && pp2 != pp0);
+
+	// temporarily steal the rest of the free pages
+	fl = page_free_list;
+	page_free_list = 0;
+
+	// should be no free memory
+	assert(!page_alloc(0));
+
+	// there is no page allocated at address 0
+	assert(page_lookup(kern_pgdir, (void *) 0x0, &ptep) == NULL);
+
+	// there is no free memory, so we can't allocate a page table
+	assert(page_insert(kern_pgdir, pp1, 0x0, PTE_W) < 0);
+
+	// free pp0 and try again: pp0 should be used for page table
+	page_free(pp0);
+	assert(page_insert(kern_pgdir, pp1, 0x0, PTE_W) == 0);
+	assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+	assert(check_va2pa(kern_pgdir, 0x0) == page2pa(pp1));
+	assert(pp1->pp_ref == 1);
+	assert(pp0->pp_ref == 1);
+
+	// should be able to map pp2 at PGSIZE because pp0 is already allocated for page table
+	assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+	assert(pp2->pp_ref == 1);
+
+	// should be no free memory
+	assert(!page_alloc(0));
+
+	// should be able to map pp2 at PGSIZE because it's already there
+	assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+	assert(pp2->pp_ref == 1);
+
+	// pp2 should NOT be on the free list
+	// could happen in ref counts are handled sloppily in page_insert
+	assert(!page_alloc(0));
+
+	// check that pgdir_walk returns a pointer to the pte
+	ptep = (pte_t *) KADDR(PTE_ADDR(kern_pgdir[PDX(PGSIZE)]));
+	assert(pgdir_walk(kern_pgdir, (void*)PGSIZE, 0) == ptep+PTX(PGSIZE));
+
+	// should be able to change permissions too.
+	assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W|PTE_U) == 0);
+	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+	assert(pp2->pp_ref == 1);
+	assert(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U);
+	assert(kern_pgdir[0] & PTE_U);
+
+	// should be able to remap with fewer permissions
+	assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+	assert(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_W);
+	assert(!(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U));
+
+	// should not be able to map at PTSIZE because need free page for page table
+	assert(page_insert(kern_pgdir, pp0, (void*) PTSIZE, PTE_W) < 0);
+
+	// insert pp1 at PGSIZE (replacing pp2)
+	assert(page_insert(kern_pgdir, pp1, (void*) PGSIZE, PTE_W) == 0);
+	assert(!(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U));
+
+	// should have pp1 at both 0 and PGSIZE, pp2 nowhere, ...
+	assert(check_va2pa(kern_pgdir, 0) == page2pa(pp1));
+	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp1));
+	// ... and ref counts should reflect this
+	assert(pp1->pp_ref == 2);
+	assert(pp2->pp_ref == 0);
+
+	// pp2 should be returned by page_alloc
+	assert((pp = page_alloc(0)) && pp == pp2);
+
+	// unmapping pp1 at 0 should keep pp1 at PGSIZE
+	page_remove(kern_pgdir, 0x0);
+	assert(check_va2pa(kern_pgdir, 0x0) == ~0);
+	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp1));
+	assert(pp1->pp_ref == 1);
+	assert(pp2->pp_ref == 0);
+
+	// test re-inserting pp1 at PGSIZE
+	assert(page_insert(kern_pgdir, pp1, (void*) PGSIZE, 0) == 0);
+	assert(pp1->pp_ref);
+	assert(pp1->pp_link == NULL);
+
+	// unmapping pp1 at PGSIZE should free it
+	page_remove(kern_pgdir, (void*) PGSIZE);
+	assert(check_va2pa(kern_pgdir, 0x0) == ~0);
+	assert(check_va2pa(kern_pgdir, PGSIZE) == ~0);
+	assert(pp1->pp_ref == 0);
+	assert(pp2->pp_ref == 0);
+
+	// so it should be returned by page_alloc
+	assert((pp = page_alloc(0)) && pp == pp1);
+
+	// should be no free memory
+	assert(!page_alloc(0));
+
+	// forcibly take pp0 back
+	assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+	kern_pgdir[0] = 0;
+	assert(pp0->pp_ref == 1);
+	pp0->pp_ref = 0;
+
+	// check pointer arithmetic in pgdir_walk
+	page_free(pp0);
+	va = (void*)(PGSIZE * NPDENTRIES + PGSIZE);
+	ptep = pgdir_walk(kern_pgdir, va, 1);
+	ptep1 = (pte_t *) KADDR(PTE_ADDR(kern_pgdir[PDX(va)]));
+	assert(ptep == ptep1 + PTX(va));
+	kern_pgdir[PDX(va)] = 0;
+	pp0->pp_ref = 0;
+
+	// check that new page tables get cleared
+	memset(page2kva(pp0), 0xFF, PGSIZE);
+	page_free(pp0);
+	pgdir_walk(kern_pgdir, 0x0, 1);
+	ptep = (pte_t *) page2kva(pp0);
+	for(i=0; i<NPTENTRIES; i++)
+		assert((ptep[i] & PTE_P) == 0);
+	kern_pgdir[0] = 0;
+	pp0->pp_ref = 0;
+
+	// give free list back
+	page_free_list = fl;
+
+	// free the pages we took
+	page_free(pp0);
+	page_free(pp1);
+	page_free(pp2);
+
+	cprintf("check_page() succeeded!\n");
+}
+
+// check page_insert, page_remove, &c, with an installed kern_pgdir
+static void
+check_page_installed_pgdir(void)
+{
+	struct PageInfo *pp, *pp0, *pp1, *pp2;
+	struct PageInfo *fl;
+	pte_t *ptep, *ptep1;
+	uintptr_t va;
+	int i;
+
+	// check that we can read and write installed pages
+	pp1 = pp2 = 0;
+	assert((pp0 = page_alloc(0)));
+	assert((pp1 = page_alloc(0)));
+	assert((pp2 = page_alloc(0)));
+	page_free(pp0);
+	memset(page2kva(pp1), 1, PGSIZE);
+	memset(page2kva(pp2), 2, PGSIZE);
+	page_insert(kern_pgdir, pp1, (void*) PGSIZE, PTE_W);
+	assert(pp1->pp_ref == 1);
+	assert(*(uint32_t *)PGSIZE == 0x01010101U);
+	page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W);
+	assert(*(uint32_t *)PGSIZE == 0x02020202U);
+	assert(pp2->pp_ref == 1);
+	assert(pp1->pp_ref == 0);
+	*(uint32_t *)PGSIZE = 0x03030303U;
+	assert(*(uint32_t *)page2kva(pp2) == 0x03030303U);
+	page_remove(kern_pgdir, (void*) PGSIZE);
+	assert(pp2->pp_ref == 0);
+
+	// forcibly take pp0 back
+	assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+	kern_pgdir[0] = 0;
+	assert(pp0->pp_ref == 1);
+	pp0->pp_ref = 0;
+
+	// free the pages we took
+	page_free(pp0);
+
+	cprintf("check_page_installed_pgdir() succeeded!\n");
+}
diff --git a/kern/pmap.h~ b/kern/pmap.h~
new file mode 100644
index 0000000..950cca1
--- /dev/null
+++ b/kern/pmap.h~
@@ -0,0 +1,87 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_PMAP_H
+#define JOS_KERN_PMAP_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+#include <inc/memlayout.h>
+#include <inc/assert.h>
+
+extern char bootstacktop[], bootstack[];
+
+extern struct PageInfo *pages;
+extern size_t npages;
+
+extern pde_t *kern_pgdir;
+
+
+/* This macro takes a kernel virtual address -- an address that points above
+ * KERNBASE, where the machine's maximum 256MB of physical memory is mapped --
+ * and returns the corresponding physical address.  It panics if you pass it a
+ * non-kernel virtual address.
+ */
+#define PADDR(kva) _paddr(__FILE__, __LINE__, kva)
+
+static inline physaddr_t
+_paddr(const char *file, int line, void *kva)
+{
+	if ((uint32_t)kva < KERNBASE)
+		_panic(file, line, "PADDR called with invalid kva %08lx", kva);
+	return (physaddr_t)kva - KERNBASE;
+}
+
+/* This macro takes a physical address and returns the corresponding kernel
+ * virtual address.  It panics if you pass an invalid physical address. */
+#define KADDR(pa) _kaddr(__FILE__, __LINE__, pa)
+
+static inline void*
+_kaddr(const char *file, int line, physaddr_t pa)
+{
+	if (PGNUM(pa) >= npages)
+		_panic(file, line, "KADDR called with invalid pa %08lx", pa);
+	return (void *)(pa + KERNBASE);
+}
+
+
+enum {
+	// For page_alloc, zero the returned physical page.
+	ALLOC_ZERO = 1<<0,
+};
+
+void	mem_init(void);
+
+void	page_init(void);
+struct PageInfo *page_alloc(int alloc_flags);
+void	page_free(struct PageInfo *pp);
+int	page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm);
+void	page_remove(pde_t *pgdir, void *va);
+struct PageInfo *page_lookup(pde_t *pgdir, void *va, pte_t **pte_store);
+void	page_decref(struct PageInfo *pp);
+
+void	tlb_invalidate(pde_t *pgdir, void *va);
+
+static inline physaddr_t
+page2pa(struct PageInfo *pp)
+{
+	return (pp - pages) << PGSHIFT;
+}
+
+static inline struct PageInfo*
+pa2page(physaddr_t pa)
+{
+	if (PGNUM(pa) >= npages)
+		panic("pa2page called with invalid pa");
+	return &pages[PGNUM(pa)];
+}
+
+static inline void*
+page2kva(struct PageInfo *pp)
+{
+	return KADDR(page2pa(pp));
+}
+
+pte_t *pgdir_walk(pde_t *pgdir, const void *va, int create);
+
+#endif /* !JOS_KERN_PMAP_H */
diff --git a/lib/printfmt.c b/lib/printfmt.c
index 28e01c9..50b0aa9 100644
--- a/lib/printfmt.c
+++ b/lib/printfmt.c
@@ -7,6 +7,7 @@
 #include <inc/string.h>
 #include <inc/stdarg.h>
 #include <inc/error.h>
+#include <inc/color.h>
 
 /*
  * Space or zero padding and a field width are supported for the numeric
@@ -92,6 +93,33 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
 		while ((ch = *(unsigned char *) fmt++) != '%') {
 			if (ch == '\0')
 				return;
+			else if(ch == '\033'){
+				if((ch = *(unsigned char *) fmt++) != '[') {
+				    putch(ch, putdat);
+				    continue;
+				}
+				BG_COLOR = *(unsigned char *) fmt++;
+				FG_COLOR = *(unsigned char *) fmt++;
+
+				if(BG_COLOR >= '0' && BG_COLOR <= '9')
+				    BG_COLOR -= '0';
+				else if(BG_COLOR >= 'a' && BG_COLOR <= 'f')
+				    BG_COLOR = BG_COLOR - 'a' + 10;
+				else if(BG_COLOR >= 'A' && BG_COLOR <= 'F')
+				    BG_COLOR = BG_COLOR - 'A' + 10;
+				else BG_COLOR = 0;
+
+				if(FG_COLOR >= '0' && FG_COLOR <= '9')
+				    FG_COLOR -= '0';
+				else if(FG_COLOR >= 'a' && FG_COLOR <= 'f')
+				    FG_COLOR = FG_COLOR - 'a' + 10;
+				else if(FG_COLOR >= 'A' && FG_COLOR <= 'F')
+				    FG_COLOR = FG_COLOR - 'A' + 10;
+				else BG_COLOR = 7;
+
+				COLOR = (BG_COLOR << 12) | (FG_COLOR << 8);
+				continue;
+			}	
 			putch(ch, putdat);
 		}
 
@@ -205,11 +233,9 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
 
 		// (unsigned) octal
 		case 'o':
-			// Replace this with your code.
-			putch('X', putdat);
-			putch('X', putdat);
-			putch('X', putdat);
-			break;
+			num = getuint(&ap,lflag);
+			base = 8;
+			goto number;
 
 		// pointer
 		case 'p':
@@ -231,7 +257,7 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
 		// escaped '%' character
 		case '%':
 			putch(ch, putdat);
-			break;
+			break;			
 
 		// unrecognized escape sequence - just print it literally
 		default:
diff --git a/tmp/lab1diff.patch b/tmp/lab1diff.patch
new file mode 100644
index 0000000..5964317
--- /dev/null
+++ b/tmp/lab1diff.patch
@@ -0,0 +1,150 @@
+diff --git a/inc/color.h b/inc/color.h
+new file mode 100644
+index 0000000..ed09ec1
+--- /dev/null
++++ b/inc/color.h
+@@ -0,0 +1,3 @@
++int FG_COLOR;
++int BG_COLOR;
++int COLOR;
+diff --git a/kern/console.c b/kern/console.c
+index 7d312a7..aba428e 100644
+--- a/kern/console.c
++++ b/kern/console.c
+@@ -5,6 +5,7 @@
+ #include <inc/kbdreg.h>
+ #include <inc/string.h>
+ #include <inc/assert.h>
++#include <inc/color.h>
+ 
+ #include <kern/console.h>
+ 
+@@ -164,8 +165,7 @@ cga_putc(int c)
+ {
+ 	// if no attribute given, then use black on white
+ 	if (!(c & ~0xFF))
+-		c |= 0x0700;
+-
++	   	c |= COLOR;
+ 	switch (c & 0xff) {
+ 	case '\b':
+ 		if (crt_pos > 0) {
+diff --git a/kern/kdebug.c b/kern/kdebug.c
+index 9547143..a573a6c 100644
+--- a/kern/kdebug.c
++++ b/kern/kdebug.c
+@@ -179,6 +179,9 @@ debuginfo_eip(uintptr_t addr, struct Eipdebuginfo *info)
+ 	//	Look at the STABS documentation and <inc/stab.h> to find
+ 	//	which one.
+ 	// Your code here.
++		stab_binsearch(stabs, &lline, &rline, N_SLINE, addr);
++		if (lline <= rline) info->eip_line = lline - lfun;
++		else return -1;
+ 
+ 
+ 	// Search backwards from the line number for the relevant filename
+diff --git a/kern/monitor.c b/kern/monitor.c
+index e137e92..db7917c 100644
+--- a/kern/monitor.c
++++ b/kern/monitor.c
+@@ -57,7 +57,29 @@ mon_kerninfo(int argc, char **argv, struct Trapframe *tf)
+ int
+ mon_backtrace(int argc, char **argv, struct Trapframe *tf)
+ {
+-	// Your code here.
++	int *ebp, eip, *old_ebp;
++	int ary[5]={};
++
++	cprintf("Stack backtrace:\n");
++	
++	ebp=(int *)read_ebp();
++	while((int)ebp!=0)
++	{
++		old_ebp=(int *)*(ebp);
++		eip=*(ebp+1);
++		for(int i=0;i<5;++i)
++		{
++			int j=i+2;
++			ary[i]=*(ebp+j);
++		}
++		struct Eipdebuginfo eip_info;
++		debuginfo_eip((uintptr_t)eip, &eip_info);
++		cprintf("\033[16ebp %08x eip %08x args %08x %08x %08x %08x %08x\n",ebp,eip,ary[0],ary[1],ary[2],ary[3],ary[4]);
++		cprintf("\033[28	%s:%d:", eip_info.eip_file, eip_info.eip_line);
++		cprintf("\033[3a %.*s+%d\n", eip_info.eip_fn_namelen, eip_info.eip_fn_name, eip - eip_info.eip_fn_addr);
++		ebp=old_ebp;
++	}
++	
+ 	return 0;
+ }
+ 
+diff --git a/lib/printfmt.c b/lib/printfmt.c
+index 28e01c9..50b0aa9 100644
+--- a/lib/printfmt.c
++++ b/lib/printfmt.c
+@@ -7,6 +7,7 @@
+ #include <inc/string.h>
+ #include <inc/stdarg.h>
+ #include <inc/error.h>
++#include <inc/color.h>
+ 
+ /*
+  * Space or zero padding and a field width are supported for the numeric
+@@ -92,6 +93,33 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
+ 		while ((ch = *(unsigned char *) fmt++) != '%') {
+ 			if (ch == '\0')
+ 				return;
++			else if(ch == '\033'){
++				if((ch = *(unsigned char *) fmt++) != '[') {
++				    putch(ch, putdat);
++				    continue;
++				}
++				BG_COLOR = *(unsigned char *) fmt++;
++				FG_COLOR = *(unsigned char *) fmt++;
++
++				if(BG_COLOR >= '0' && BG_COLOR <= '9')
++				    BG_COLOR -= '0';
++				else if(BG_COLOR >= 'a' && BG_COLOR <= 'f')
++				    BG_COLOR = BG_COLOR - 'a' + 10;
++				else if(BG_COLOR >= 'A' && BG_COLOR <= 'F')
++				    BG_COLOR = BG_COLOR - 'A' + 10;
++				else BG_COLOR = 0;
++
++				if(FG_COLOR >= '0' && FG_COLOR <= '9')
++				    FG_COLOR -= '0';
++				else if(FG_COLOR >= 'a' && FG_COLOR <= 'f')
++				    FG_COLOR = FG_COLOR - 'a' + 10;
++				else if(FG_COLOR >= 'A' && FG_COLOR <= 'F')
++				    FG_COLOR = FG_COLOR - 'A' + 10;
++				else BG_COLOR = 7;
++
++				COLOR = (BG_COLOR << 12) | (FG_COLOR << 8);
++				continue;
++			}	
+ 			putch(ch, putdat);
+ 		}
+ 
+@@ -205,11 +233,9 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
+ 
+ 		// (unsigned) octal
+ 		case 'o':
+-			// Replace this with your code.
+-			putch('X', putdat);
+-			putch('X', putdat);
+-			putch('X', putdat);
+-			break;
++			num = getuint(&ap,lflag);
++			base = 8;
++			goto number;
+ 
+ 		// pointer
+ 		case 'p':
+@@ -231,7 +257,7 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
+ 		// escaped '%' character
+ 		case '%':
+ 			putch(ch, putdat);
+-			break;
++			break;			
+ 
+ 		// unrecognized escape sequence - just print it literally
+ 		default:
